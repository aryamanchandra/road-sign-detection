{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOnLgbFVCW5wgtYTDUGx3lx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3umPxs3uMU-"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "nH1gfTldvQR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://btsd.ethz.ch/shareddata/BelgiumTSC/BelgiumTSC_Training.zip"
      ],
      "metadata": {
        "id": "QuDbRV6yudHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"BelgiumTSC_Training.zip\""
      ],
      "metadata": {
        "id": "7TwigF5mwRFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://btsd.ethz.ch/shareddata/BelgiumTSC/BelgiumTSC_Testing.zip"
      ],
      "metadata": {
        "id": "E0sNn1782rGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"BelgiumTSC_Testing.zip\""
      ],
      "metadata": {
        "id": "RT-ss4ft2uBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout"
      ],
      "metadata": {
        "id": "YHlOJ9Ds3KL8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model\n",
        "def create_model(input_shape, num_classes):\n",
        "    base_model = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "e38ALR3O3Il3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset paths and parameters\n",
        "train_data_dir = 'Training'\n",
        "valid_data_dir = 'Testing'\n",
        "input_shape = (224, 224, 3)  # Adjust based on your image dimensions\n",
        "num_classes = 62  # Number of road sign classes"
      ],
      "metadata": {
        "id": "_9qjMhDU3LfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = create_model(input_shape, num_classes)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WFtZJ8ZU3MyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing and augmentation\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1.0 / 255\n",
        ")\n"
      ],
      "metadata": {
        "id": "OXDI5uPR3OtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_data_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIXelP_y3QBz",
        "outputId": "1f41830b-a187-422b-b79c-24eb155f2e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4575 images belonging to 62 classes.\n",
            "Found 2520 images belonging to 62 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 10  # Adjust based on your dataset and computational resources\n",
        "model.fit(train_generator, epochs=epochs, validation_data=valid_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfWrNsXu3R3T",
        "outputId": "c0a1da9a-80f4-4953-b4eb-e5e175224c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "143/143 [==============================] - 85s 597ms/step - loss: 0.2232 - accuracy: 0.9305 - val_loss: 0.2325 - val_accuracy: 0.9413\n",
            "Epoch 2/10\n",
            "143/143 [==============================] - 85s 595ms/step - loss: 0.1989 - accuracy: 0.9364 - val_loss: 0.3029 - val_accuracy: 0.9290\n",
            "Epoch 3/10\n",
            "143/143 [==============================] - 86s 601ms/step - loss: 0.1922 - accuracy: 0.9366 - val_loss: 0.2631 - val_accuracy: 0.9365\n",
            "Epoch 4/10\n",
            "143/143 [==============================] - 85s 594ms/step - loss: 0.1660 - accuracy: 0.9478 - val_loss: 0.2268 - val_accuracy: 0.9437\n",
            "Epoch 5/10\n",
            "143/143 [==============================] - 85s 596ms/step - loss: 0.1585 - accuracy: 0.9504 - val_loss: 0.2424 - val_accuracy: 0.9393\n",
            "Epoch 6/10\n",
            "143/143 [==============================] - 86s 597ms/step - loss: 0.3249 - accuracy: 0.9121 - val_loss: 0.2402 - val_accuracy: 0.9484\n",
            "Epoch 7/10\n",
            "143/143 [==============================] - 85s 594ms/step - loss: 0.1532 - accuracy: 0.9495 - val_loss: 0.2635 - val_accuracy: 0.9429\n",
            "Epoch 8/10\n",
            "143/143 [==============================] - 86s 598ms/step - loss: 0.1253 - accuracy: 0.9580 - val_loss: 0.1956 - val_accuracy: 0.9631\n",
            "Epoch 9/10\n",
            "143/143 [==============================] - 85s 594ms/step - loss: 0.1520 - accuracy: 0.9532 - val_loss: 0.1972 - val_accuracy: 0.9567\n",
            "Epoch 10/10\n",
            "143/143 [==============================] - 84s 585ms/step - loss: 0.1574 - accuracy: 0.9558 - val_loss: 0.2787 - val_accuracy: 0.9393\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x790dd35cba90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('road_sign_detection_model.h5')"
      ],
      "metadata": {
        "id": "kRFvwRpNxI5O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}